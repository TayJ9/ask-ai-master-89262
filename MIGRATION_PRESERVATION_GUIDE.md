# Migration Preservation Guide: OpenAI ‚Üí ElevenLabs

## ‚ö†Ô∏è CRITICAL: Components That MUST NOT Be Changed

This document identifies all critical components that should be preserved during the migration from OpenAI Realtime API to ElevenLabs Conversational AI. These components represent core business logic, user experience, and system architecture that should remain intact.

---

## 1. System Prompt & Interview Logic (MUST PRESERVE)

### File: `backend/voiceServer.js`
### Function: `createSystemPrompt(candidateContext)`

**CRITICAL - DO NOT MODIFY:**
- ‚úÖ Complete system prompt text (lines 71-180)
- ‚úÖ Major category detection logic (CS, Finance, Engineering, Business, Psychology)
- ‚úÖ Technical difficulty calculation based on academic year
- ‚úÖ Behavioral vs technical question ratio calculation
- ‚úÖ Interview structure and timing (15-20 minutes)
- ‚úÖ Tone and approach guidelines (warm, encouraging, confidence-building)
- ‚úÖ Question framing and response handling principles
- ‚úÖ Dynamic adjustment logic based on candidate responses

**Why Preserve:**
- This is the core interview intelligence that makes the system effective
- Years of refinement in question tailoring and candidate assessment
- Critical for maintaining interview quality regardless of voice provider

**Migration Note:**
- The system prompt text should be passed to ElevenLabs API in the same format
- Only the API call structure changes, not the prompt content

---

## 2. Frontend Component Structure (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 2.1 Component Props Interface
```typescript
interface VoiceInterviewWebSocketProps {
  sessionId: string;
  candidateContext: {
    name: string;
    major: string;
    year: string;
    skills?: string[];
    experience?: string;
    education?: string;
    summary?: string;
  };
  onComplete: (results?: any) => void;
}
```
- ‚úÖ Keep exact same interface - used by parent components

#### 2.2 State Management
- ‚úÖ `isConnected`, `isInterviewActive`, `isRecording`, `isPlaying`, `isProcessing`
- ‚úÖ `statusMessage` - critical for user feedback
- ‚úÖ `transcripts` - transcript display and management
- ‚úÖ `conversationState` - state machine: `'ai_speaking' | 'listening' | 'user_speaking' | 'processing'`
- ‚úÖ All refs: `wsRef`, `audioContextRef`, `mediaStreamRef`, `audioQueueRef`, etc.

**Why Preserve:**
- State machine ensures proper conversation flow
- User experience depends on accurate state transitions
- Audio queue management prevents playback issues

---

## 3. Audio Processing Pipeline (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 3.1 Audio Format Conversion
- ‚úÖ `convertToPCM16(float32Array)` - converts microphone input to PCM16
- ‚úÖ `convertPCM16ToFloat32(pcm16Array)` - converts received audio to Float32
- ‚úÖ AudioContext sample rate: **24000 Hz** (must match ElevenLabs output)

#### 3.2 Audio Queue Management
- ‚úÖ `queueAudioChunk(arrayBuffer)` - queues audio chunks for playback
- ‚úÖ `processAudioQueue()` - processes queue with precise timing
- ‚úÖ Queue size limits: MAX_QUEUE_SIZE = 30, WARN_QUEUE_SIZE = 20
- ‚úÖ Queue clearing logic on interruption
- ‚úÖ Timing drift handling and chunk dropping logic

#### 3.3 Audio Playback
- ‚úÖ `nextPlayTimeRef` - precise scheduling for seamless playback
- ‚úÖ `activeSourcesRef` - tracks active audio sources for cleanup
- ‚úÖ Gain node configuration (0.85 gain to prevent clipping)
- ‚úÖ Audio source cleanup on interruption

**Why Preserve:**
- Prevents audio crackling, popping, and synchronization issues
- Ensures smooth playback regardless of network conditions
- Critical for professional audio quality

**Migration Note:**
- Verify ElevenLabs audio output format matches (PCM16, 24kHz)
- May need to adjust decoder if format differs, but keep queue logic

---

## 4. Conversation State Machine (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 4.1 State Transitions
- ‚úÖ `ai_speaking` ‚Üí `listening` ‚Üí `user_speaking` ‚Üí `processing` ‚Üí `ai_speaking`
- ‚úÖ State transition logging (`logStateTransition`, `setConversationStateWithLogging`)
- ‚úÖ State timeout handling (30s max for AI response)
- ‚úÖ State-based UI updates and status messages

#### 4.2 Turn-Taking Logic
- ‚úÖ User interruption detection and handling
- ‚úÖ AI response cancellation on user speech start
- ‚úÖ Queue clearing on interruption
- ‚úÖ Transcript preservation during interruptions

**Why Preserve:**
- Ensures natural conversation flow
- Prevents AI from interrupting users
- Critical for interview quality

**Migration Note:**
- ElevenLabs may have different interruption signals - adapt API calls, not state logic

---

## 5. Transcript Handling (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 5.1 Transcript State Management
- ‚úÖ `TranscriptMessage` interface: `type`, `text`, `isFinal`, `timestamp`
- ‚úÖ Transcript accumulation logic (non-final + final updates)
- ‚úÖ Pending transcript handling during interruptions
- ‚úÖ Transcript display in UI

#### 5.2 Transcript Processing
- ‚úÖ AI transcript delta accumulation
- ‚úÖ Student transcript delta accumulation
- ‚úÖ Final transcript marking
- ‚úÖ Transcript preservation on interruption

**Why Preserve:**
- Users rely on accurate transcripts
- Transcript accuracy is critical for interview assessment
- Display logic is tightly coupled with state management

**Migration Note:**
- ElevenLabs transcript format may differ - adapt parsing, not display logic

---

## 6. WebSocket Message Handling (ADAPT, DON'T REWRITE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`
### File: `backend/voiceServer.js`

**PRESERVE STRUCTURE, ADAPT MESSAGES:**

#### 6.1 Message Types to Preserve
- ‚úÖ `connected` - connection confirmation
- ‚úÖ `interview_starting` - interview initialization
- ‚úÖ `interview_started` - interview active
- ‚úÖ `ai_transcription` - AI speech transcript
- ‚úÖ `student_transcription` - user speech transcript
- ‚úÖ `student_speech_started` - user interruption detection
- ‚úÖ `student_speech_ended` - user finished speaking
- ‚úÖ `ai_response_done` - AI finished responding
- ‚úÖ `ai_audio_done` - AI audio stream complete
- ‚úÖ `error` - error handling

#### 6.2 Message Flow Logic
- ‚úÖ Message routing and handling structure
- ‚úÖ Error handling and retry logic
- ‚úÖ Connection lifecycle management

**Why Preserve:**
- Message structure is used throughout the frontend
- Changing message types breaks UI components
- Error handling is critical for reliability

**Migration Note:**
- Map ElevenLabs events to existing message types
- Keep message structure identical, only change backend event mapping

---

## 7. UI Components & User Experience (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 7.1 UI Elements
- ‚úÖ Status indicators (AI speaking, recording, listening, processing)
- ‚úÖ Microphone button and visual feedback
- ‚úÖ Transcript display with AI/Student differentiation
- ‚úÖ End interview button
- ‚úÖ Loading states and error messages

#### 7.2 User Feedback
- ‚úÖ Status messages for each conversation state
- ‚úÖ Toast notifications for errors
- ‚úÖ Visual indicators (AISpeakingIndicator, animated backgrounds)
- ‚úÖ Button states and disabled states

**Why Preserve:**
- User experience is polished and tested
- Visual feedback is critical for user confidence
- UI consistency maintains professional appearance

---

## 8. Candidate Context Handling (MUST PRESERVE)

### File: `backend/voiceServer.js`
### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**CRITICAL - DO NOT MODIFY:**

#### 8.1 Context Structure
- ‚úÖ Candidate information: name, major, year, skills, experience, education, summary
- ‚úÖ Context validation before interview start
- ‚úÖ Context passing to system prompt

#### 8.2 Context Usage
- ‚úÖ Major-based question tailoring
- ‚úÖ Year-based difficulty adjustment
- ‚úÖ Skills-based question selection
- ‚úÖ Experience-based follow-ups

**Why Preserve:**
- Core personalization logic
- Interview quality depends on context-aware questions
- Business logic for candidate assessment

---

## 9. Error Handling & Resilience (MUST PRESERVE)

### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`
### File: `backend/voiceServer.js`

**CRITICAL - DO NOT MODIFY:**

#### 9.1 Connection Resilience
- ‚úÖ WebSocket retry logic (max 3 retries, exponential backoff)
- ‚úÖ Connection timeout handling
- ‚úÖ Reconnection on unexpected close

#### 9.2 Error Recovery
- ‚úÖ Audio context suspension handling
- ‚úÖ Microphone permission error handling
- ‚úÖ API error message formatting
- ‚úÖ User-friendly error messages

**Why Preserve:**
- Critical for production reliability
- User experience during failures
- Prevents data loss and session corruption

---

## 10. Logging & Monitoring (PRESERVE STRUCTURE)

### File: `backend/voiceServer.js`
### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**PRESERVE LOGGING STRUCTURE:**

#### 10.1 Backend Logging
- ‚úÖ Model name logging
- ‚úÖ Session configuration logging
- ‚úÖ Turn detection event logging
- ‚úÖ Session metrics (duration, message counts)

#### 10.2 Frontend Logging
- ‚úÖ Queue size monitoring
- ‚úÖ State transition logging
- ‚úÖ Turn-taking timing logs
- ‚úÖ Audio chunk metrics

**Why Preserve:**
- Critical for debugging
- Performance monitoring
- Issue diagnosis

**Migration Note:**
- Keep logging structure, adapt to ElevenLabs events

---

## 11. Configuration Constants (VERIFY COMPATIBILITY)

### File: `backend/voiceServer.js`
### File: `frontend/src/components/VoiceInterviewWebSocket.tsx`

**VERIFY THESE MATCH ELEVENLABS:**

- ‚ö†Ô∏è Audio sample rate: **24000 Hz** (must match ElevenLabs)
- ‚ö†Ô∏è Audio format: **PCM16** (verify ElevenLabs supports this)
- ‚ö†Ô∏è Turn detection: **server_vad** (ElevenLabs may use different VAD)
- ‚ö†Ô∏è Silence duration: **2500ms** (may need adjustment for ElevenLabs)
- ‚ö†Ô∏è Queue limits: **MAX_QUEUE_SIZE = 30** (keep if working)

---

## 12. Files That Should NOT Be Modified

### Core Business Logic Files:
- ‚úÖ `backend/voiceServer.js` - `createSystemPrompt()` function (lines 10-180)
- ‚úÖ `frontend/src/components/VoiceInterviewWebSocket.tsx` - Component structure and state management
- ‚úÖ `frontend/src/components/InterviewSession.tsx` - Parent component integration

### Configuration Files:
- ‚úÖ `package.json` - Dependencies (add ElevenLabs SDK, don't remove existing)
- ‚úÖ `tsconfig.json` - TypeScript configuration
- ‚úÖ `vercel.json` - Deployment configuration

---

## Migration Strategy

### Phase 1: API Layer Only
1. ‚úÖ Create new `createElevenLabsConnection()` function (parallel to `createOpenAIConnection()`)
2. ‚úÖ Map ElevenLabs events to existing message types
3. ‚úÖ Keep all frontend code unchanged
4. ‚úÖ Keep system prompt unchanged

### Phase 2: Testing
1. ‚úÖ Test with same candidate contexts
2. ‚úÖ Verify audio quality matches or exceeds OpenAI
3. ‚úÖ Verify transcript accuracy
4. ‚úÖ Verify turn-taking behavior

### Phase 3: Switchover
1. ‚úÖ Add feature flag to switch between providers
2. ‚úÖ Test both providers in parallel
3. ‚úÖ Gradually migrate users
4. ‚úÖ Keep OpenAI code as fallback

---

## Rollback Plan

If migration fails:
1. ‚úÖ Revert to git tag: `openai-stable-checkpoint`
2. ‚úÖ Restore `OPENAI_MODEL` constant
3. ‚úÖ Restore `createOpenAIConnection()` usage
4. ‚úÖ All preserved components remain intact

---

## Summary: What Changes vs What Stays

### ‚úÖ STAYS THE SAME (Core Business Logic):
- System prompt and interview logic
- Frontend component structure
- Audio processing pipeline
- Conversation state machine
- Transcript handling
- UI components and UX
- Candidate context handling
- Error handling
- Logging structure

### üîÑ CHANGES (API Integration Only):
- WebSocket connection function (`createOpenAIConnection` ‚Üí `createElevenLabsConnection`)
- API endpoint URLs
- Message event mapping (ElevenLabs events ‚Üí existing message types)
- Audio decoder (if format differs)
- Environment variables (API keys)

---

## Critical Success Factors

1. ‚úÖ **Preserve system prompt** - This is your competitive advantage
2. ‚úÖ **Keep audio pipeline** - Prevents quality issues
3. ‚úÖ **Maintain state machine** - Ensures conversation flow
4. ‚úÖ **Preserve UI/UX** - User experience is polished
5. ‚úÖ **Keep error handling** - Production reliability

---

## Questions to Answer Before Migration

1. ‚úÖ Does ElevenLabs support PCM16 at 24kHz?
2. ‚úÖ What is ElevenLabs transcript format?
3. ‚úÖ How does ElevenLabs handle interruptions?
4. ‚úÖ What is ElevenLabs latency compared to OpenAI?
5. ‚úÖ Does ElevenLabs support system prompts?
6. ‚úÖ What is ElevenLabs pricing vs OpenAI?

---

**Last Updated:** Before ElevenLabs Migration
**Checkpoint Tag:** `openai-stable-checkpoint`
**Commit Hash:** (will be set when tag is created)

